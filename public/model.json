{"format": "graph-model", "generatedBy": "1.15.2", "convertedBy": "TensorFlow.js Converter v1.7.4r1", "userDefinedMetadata": {"signature": {"inputs": {"label_ids:0": {"name": "label_ids:0", "dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "-1"}]}}, "module/cls/predictions/transform/dense/bias:0": {"name": "module/cls/predictions/transform/dense/bias:0", "dtype": "DT_RESOURCE", "tensorShape": {}}, "segment_ids:0": {"name": "segment_ids:0", "dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "-1"}, {"size": "128"}]}}, "module/cls/predictions/transform/LayerNorm/gamma:0": {"name": "module/cls/predictions/transform/LayerNorm/gamma:0", "dtype": "DT_RESOURCE", "tensorShape": {}}, "module/cls/predictions/output_bias:0": {"name": "module/cls/predictions/output_bias:0", "dtype": "DT_RESOURCE", "tensorShape": {}}, "module/cls/predictions/transform/dense/kernel:0": {"name": "module/cls/predictions/transform/dense/kernel:0", "dtype": "DT_RESOURCE", "tensorShape": {}}, "input_ids:0": {"name": "input_ids:0", "dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "-1"}, {"size": "128"}]}}, "input_mask:0": {"name": "input_mask:0", "dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "-1"}, {"size": "128"}]}}, "module/cls/predictions/transform/LayerNorm/beta:0": {"name": "module/cls/predictions/transform/LayerNorm/beta:0", "dtype": "DT_RESOURCE", "tensorShape": {}}}, "outputs": {"loss/Squeeze:0": {"name": "loss/Squeeze:0", "dtype": "DT_INT32", "tensorShape": {"unknownRank": true}}, "loss/LogSoftmax:0": {"name": "loss/LogSoftmax:0", "dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "-1"}, {"size": "2"}]}}}}}, "modelTopology": {"node": [{"name": "label_ids", "op": "Placeholder", "attr": {"dtype": {"type": "DT_INT32"}, "shape": {"shape": {"dim": [{"size": "-1"}]}}}}, {"name": "loss/dropout/rate", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}}}, {"name": "loss/dropout/truediv", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}}}, {"name": "module/bert/encoder/layer_11/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/attention/output/LayerNorm/beta", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_11/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/attention/self/query/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_11/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/output/LayerNorm/beta", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_10/output/LayerNorm/gamma", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_10/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/attention/self/value/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/attention/output/dense/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_10/attention/output/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_9/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/self/query/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_9/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/self/key/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_8/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/output/LayerNorm/gamma", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_8/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/attention/self/key/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_8/attention/self/key/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_7/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/output/LayerNorm/beta", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_6/output/LayerNorm/gamma", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_6/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_6/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/output/LayerNorm/gamma", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_5/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_5/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/attention/self/key/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_4/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/attention/self/query/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_3/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/output/LayerNorm/beta", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_2/output/LayerNorm/gamma", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_2/attention/output/LayerNorm/beta", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_2/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/output/LayerNorm/gamma", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_1/attention/output/LayerNorm/beta", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_1/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/attention/self/query/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_1/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/attention/output/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/attention/output/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/attention/self/query/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/attention/self/query/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/attention/self/key/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/attention/self/key/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1/y", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "input_mask", "op": "Placeholder", "attr": {"dtype": {"type": "DT_INT32"}, "shape": {"shape": {"dim": [{"size": "-1"}, {"size": "128"}]}}}}, {"name": "module_apply_tokens/bert/encoder/ones/packed/2", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/Reshape_1/shape", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "2"}]}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module/bert/encoder/layer_0/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/attention/self/value/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_0/attention/output/dense/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_0/attention/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/intermediate/dense/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}}}, {"name": "module/bert/encoder/layer_0/intermediate/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_0/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/attention/self/value/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_1/attention/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/attention/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/intermediate/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}}}, {"name": "module/bert/encoder/layer_1/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_1/output/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_2/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/attention/self/value/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/attention/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/attention/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_2/intermediate/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}}}, {"name": "module/bert/encoder/layer_2/output/dense/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_2/output/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_3/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/attention/self/value/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_3/attention/output/dense/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_3/attention/output/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_3/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/intermediate/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}}}, {"name": "module/bert/encoder/layer_3/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_3/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/self/value/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/attention/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/intermediate/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_4/output/dense/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_4/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/attention/self/value/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_5/attention/self/value/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/attention/output/dense/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_5/attention/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/intermediate/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}}}, {"name": "module/bert/encoder/layer_5/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_5/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/attention/self/value/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/attention/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/attention/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/intermediate/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_6/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/self/value/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_7/attention/self/value/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/attention/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/intermediate/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_7/output/dense/kernel", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_7/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/attention/self/value/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/attention/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/attention/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/intermediate/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_8/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/self/value/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/attention/output/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_9/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/intermediate/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_9/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/intermediate/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_10/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/attention/self/value/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/attention/self/value/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape/2", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape/3", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "4"}]}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module/bert/encoder/layer_11/attention/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/attention/output/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "module/bert/encoder/layer_11/intermediate/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/intermediate/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/output/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "3072"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/encoder/layer_11/output/dense/bias", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/embeddings/LayerNorm/beta", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/embeddings/LayerNorm/gamma", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/embeddings/position_embeddings", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "512"}, {"size": "768"}]}}}}}, {"name": "module_apply_tokens/bert/embeddings/one_hot/depth", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}}}, {"name": "module_apply_tokens/bert/embeddings/one_hot/off_value", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {}}}}}, {"name": "module/bert/embeddings/token_type_embeddings", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "2"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/embeddings/word_embeddings", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "30522"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/embedding_lookup/axis", "op": "Const", "attr": {"dtype": {"type": "DT_INT32"}, "value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}}}, {"name": "module_apply_tokens/bert/encoder/strided_slice/stack", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "1"}]}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "input_ids", "op": "Placeholder", "attr": {"dtype": {"type": "DT_INT32"}, "shape": {"shape": {"dim": [{"size": "-1"}, {"size": "128"}]}}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape_1/shape", "op": "Const", "attr": {"dtype": {"type": "DT_INT32"}, "value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "1"}]}}}}}, {"name": "module_apply_tokens/bert/encoder/strided_slice_1/stack_1", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "1"}]}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "1"}]}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape/1", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/pooler/strided_slice/stack", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "3"}]}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/pooler/strided_slice/stack_1", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "3"}]}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/pooler/strided_slice/stack_2", "op": "Const", "attr": {"dtype": {"type": "DT_INT32"}, "value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "3"}]}}}}}, {"name": "module/bert/pooler/dense/kernel", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "module/bert/pooler/dense/bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "768"}]}}}}}, {"name": "output_weights", "op": "Const", "attr": {"value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "2"}, {"size": "768"}]}}}, "dtype": {"type": "DT_FLOAT"}}}, {"name": "output_bias", "op": "Const", "attr": {"dtype": {"type": "DT_FLOAT"}, "value": {"tensor": {"dtype": "DT_FLOAT", "tensorShape": {"dim": [{"size": "2"}]}}}}}, {"name": "loss/ArgMax/dimension", "op": "Const", "attr": {"dtype": {"type": "DT_INT32"}, "value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}}}, {"name": "module/cls/predictions/output_bias", "op": "Placeholder", "attr": {"shape": {"shape": {}}, "dtype": {"type": "DT_RESOURCE"}}}, {"name": "module/cls/predictions/transform/LayerNorm/beta", "op": "Placeholder", "attr": {"dtype": {"type": "DT_RESOURCE"}, "shape": {"shape": {}}}}, {"name": "module/cls/predictions/transform/LayerNorm/gamma", "op": "Placeholder", "attr": {"dtype": {"type": "DT_RESOURCE"}, "shape": {"shape": {}}}}, {"name": "module/cls/predictions/transform/dense/bias", "op": "Placeholder", "attr": {"dtype": {"type": "DT_RESOURCE"}, "shape": {"shape": {}}}}, {"name": "module/cls/predictions/transform/dense/kernel", "op": "Placeholder", "attr": {"dtype": {"type": "DT_RESOURCE"}, "shape": {"shape": {}}}}, {"name": "segment_ids", "op": "Placeholder", "attr": {"shape": {"shape": {"dim": [{"size": "-1"}, {"size": "128"}]}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/Shape_1", "op": "Shape", "input": ["input_mask"], "attr": {"T": {"type": "DT_INT32"}, "out_type": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/Shape", "op": "Shape", "input": ["input_ids"], "attr": {"T": {"type": "DT_INT32"}, "out_type": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/ExpandDims", "op": "ExpandDims", "input": ["input_ids", "module_apply_tokens/bert/embeddings/Reshape_1/shape"], "attr": {"Tdim": {"type": "DT_INT32"}, "T": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape_1", "op": "Reshape", "input": ["segment_ids", "module_apply_tokens/bert/embeddings/Reshape_1/shape"], "attr": {"T": {"type": "DT_INT32"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/strided_slice_3", "op": "StridedSlice", "input": ["module_apply_tokens/bert/encoder/Shape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/strided_slice_1/stack_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"Index": {"type": "DT_INT32"}, "T": {"type": "DT_INT32"}, "shrink_axis_mask": {"i": "1"}, "begin_mask": {"i": "0"}, "ellipsis_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}, "end_mask": {"i": "0"}}}, {"name": "module_apply_tokens/bert/encoder/strided_slice", "op": "StridedSlice", "input": ["module_apply_tokens/bert/encoder/Shape", "module_apply_tokens/bert/encoder/strided_slice/stack", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"shrink_axis_mask": {"i": "1"}, "begin_mask": {"i": "0"}, "ellipsis_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}, "end_mask": {"i": "0"}, "T": {"type": "DT_INT32"}, "Index": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/strided_slice_1", "op": "StridedSlice", "input": ["module_apply_tokens/bert/encoder/Shape", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/strided_slice_1/stack_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"end_mask": {"i": "0"}, "T": {"type": "DT_INT32"}, "Index": {"type": "DT_INT32"}, "shrink_axis_mask": {"i": "1"}, "ellipsis_mask": {"i": "0"}, "begin_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}}}, {"name": "module_apply_tokens/bert/embeddings/embedding_lookup", "op": "GatherV2", "input": ["module/bert/embeddings/word_embeddings", "module_apply_tokens/bert/embeddings/ExpandDims", "module_apply_tokens/bert/embeddings/embedding_lookup/axis"], "attr": {"Tparams": {"type": "DT_FLOAT"}, "Taxis": {"type": "DT_INT32"}, "batch_dims": {"i": "0"}, "Tindices": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/Shape", "op": "Shape", "input": ["module_apply_tokens/bert/embeddings/ExpandDims"], "attr": {"T": {"type": "DT_INT32"}, "out_type": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/one_hot", "op": "OneHot", "input": ["module_apply_tokens/bert/embeddings/Reshape_1", "module_apply_tokens/bert/embeddings/one_hot/depth", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/embeddings/one_hot/off_value"], "attr": {"T": {"type": "DT_FLOAT"}, "axis": {"i": "-1"}, "TI": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/Reshape/shape", "op": "Pack", "input": ["module_apply_tokens/bert/encoder/strided_slice", "module_apply_tokens/bert/encoder/ones/packed/2", "module_apply_tokens/bert/encoder/strided_slice_3"], "attr": {"T": {"type": "DT_INT32"}, "axis": {"i": "0"}, "N": {"i": "3"}}}, {"name": "module_apply_tokens/bert/encoder/ones/packed", "op": "Pack", "input": ["module_apply_tokens/bert/encoder/strided_slice", "module_apply_tokens/bert/encoder/strided_slice_1", "module_apply_tokens/bert/encoder/ones/packed/2"], "attr": {"T": {"type": "DT_INT32"}, "axis": {"i": "0"}, "N": {"i": "3"}}}, {"name": "module_apply_tokens/bert/embeddings/strided_slice", "op": "StridedSlice", "input": ["module_apply_tokens/bert/embeddings/Shape", "module_apply_tokens/bert/encoder/strided_slice/stack", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"shrink_axis_mask": {"i": "1"}, "begin_mask": {"i": "0"}, "ellipsis_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}, "end_mask": {"i": "0"}, "T": {"type": "DT_INT32"}, "Index": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/strided_slice_1", "op": "StridedSlice", "input": ["module_apply_tokens/bert/embeddings/Shape", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/strided_slice_1/stack_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"end_mask": {"i": "0"}, "T": {"type": "DT_INT32"}, "Index": {"type": "DT_INT32"}, "shrink_axis_mask": {"i": "1"}, "ellipsis_mask": {"i": "0"}, "begin_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}}}, {"name": "module_apply_tokens/bert/embeddings/MatMul", "op": "MatMul", "input": ["module_apply_tokens/bert/embeddings/one_hot", "module/bert/embeddings/token_type_embeddings"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/Reshape", "op": "Reshape", "input": ["input_mask", "module_apply_tokens/bert/encoder/Reshape/shape"], "attr": {"T": {"type": "DT_INT32"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/ones", "op": "Fill", "input": ["module_apply_tokens/bert/encoder/ones/packed", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x"], "attr": {"T": {"type": "DT_FLOAT"}, "index_type": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape/shape", "op": "Pack", "input": ["module_apply_tokens/bert/embeddings/strided_slice", "module_apply_tokens/bert/embeddings/strided_slice_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape/1"], "attr": {"N": {"i": "3"}, "T": {"type": "DT_INT32"}, "axis": {"i": "0"}}}, {"name": "module_apply_tokens/bert/encoder/Cast", "op": "Cast", "input": ["module_apply_tokens/bert/encoder/Reshape"], "attr": {"SrcT": {"type": "DT_INT32"}, "Truncate": {"b": false}, "DstT": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/embeddings/embedding_lookup", "module_apply_tokens/bert/embeddings/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/Cast", "module_apply_tokens/bert/encoder/ones"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/Shape_1", "op": "Shape", "input": ["module_apply_tokens/bert/embeddings/Reshape"], "attr": {"T": {"type": "DT_FLOAT"}, "out_type": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims", "op": "ExpandDims", "input": ["module_apply_tokens/bert/encoder/mul", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"Tdim": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/strided_slice_2", "op": "StridedSlice", "input": ["module_apply_tokens/bert/embeddings/Shape_1", "module_apply_tokens/bert/encoder/strided_slice/stack", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"shrink_axis_mask": {"i": "1"}, "ellipsis_mask": {"i": "0"}, "begin_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}, "end_mask": {"i": "0"}, "Index": {"type": "DT_INT32"}, "T": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/strided_slice_3", "op": "StridedSlice", "input": ["module_apply_tokens/bert/embeddings/Shape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/strided_slice_1/stack_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_INT32"}, "Index": {"type": "DT_INT32"}, "shrink_axis_mask": {"i": "1"}, "ellipsis_mask": {"i": "0"}, "begin_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}, "end_mask": {"i": "0"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/sub", "op": "Sub", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/Slice/begin", "op": "Const", "input": ["^module_apply_tokens/bert/embeddings/strided_slice_3"], "attr": {"dtype": {"type": "DT_INT32"}, "value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {"dim": [{"size": "2"}]}}}}}, {"name": "module_apply_tokens/bert/embeddings/Slice/size/1", "op": "Const", "input": ["^module_apply_tokens/bert/embeddings/strided_slice_3"], "attr": {"dtype": {"type": "DT_INT32"}, "value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape_3/shape/0", "op": "Const", "input": ["^module_apply_tokens/bert/embeddings/strided_slice_3"], "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape_3/shape/2", "op": "Const", "input": ["^module_apply_tokens/bert/embeddings/strided_slice_3"], "attr": {"value": {"tensor": {"dtype": "DT_INT32", "tensorShape": {}}}, "dtype": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape_2/shape", "op": "Pack", "input": ["module_apply_tokens/bert/embeddings/strided_slice_2", "module_apply_tokens/bert/embeddings/strided_slice_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape/1"], "attr": {"N": {"i": "3"}, "T": {"type": "DT_INT32"}, "axis": {"i": "0"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1/y", "module_apply_tokens/bert/encoder/layer_11/attention/self/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/Slice/size", "op": "Pack", "input": ["module_apply_tokens/bert/embeddings/strided_slice_3", "module_apply_tokens/bert/embeddings/Slice/size/1"], "attr": {"T": {"type": "DT_INT32"}, "axis": {"i": "0"}, "N": {"i": "2"}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape_3/shape", "op": "Pack", "input": ["module_apply_tokens/bert/embeddings/Reshape_3/shape/0", "module_apply_tokens/bert/embeddings/strided_slice_3", "module_apply_tokens/bert/embeddings/Reshape_3/shape/2"], "attr": {"N": {"i": "3"}, "T": {"type": "DT_INT32"}, "axis": {"i": "0"}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/embeddings/MatMul", "module_apply_tokens/bert/embeddings/Reshape_2/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/Slice", "op": "Slice", "input": ["module/bert/embeddings/position_embeddings", "module_apply_tokens/bert/embeddings/Slice/begin", "module_apply_tokens/bert/embeddings/Slice/size"], "attr": {"Index": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/add", "op": "Add", "input": ["module_apply_tokens/bert/embeddings/Reshape", "module_apply_tokens/bert/embeddings/Reshape_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/embeddings/Slice", "module_apply_tokens/bert/embeddings/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/add_1", "op": "Add", "input": ["module_apply_tokens/bert/embeddings/Reshape_3", "module_apply_tokens/bert/embeddings/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/embeddings/add_1", "module_apply_tokens/bert/encoder/strided_slice_1/stack_1"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/moments/mean", "module_apply_tokens/bert/embeddings/add_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/strided_slice_1/stack_1"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/moments/variance", "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/embeddings/LayerNorm/gamma", "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/embeddings/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/embeddings/add_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/embeddings/LayerNorm/beta", "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/Reshape_1/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/Shape_2", "op": "Shape", "input": ["module_apply_tokens/bert/embeddings/LayerNorm/batchnorm/add_1"], "attr": {"T": {"type": "DT_FLOAT"}, "out_type": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/Reshape_1", "module/bert/encoder/layer_0/attention/self/query/kernel", "module/bert/encoder/layer_0/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/Reshape_1", "module/bert/encoder/layer_0/attention/self/key/kernel", "module/bert/encoder/layer_0/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/Reshape_1", "module/bert/encoder/layer_0/attention/self/value/kernel", "module/bert/encoder/layer_0/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/strided_slice_4", "op": "StridedSlice", "input": ["module_apply_tokens/bert/encoder/Shape_2", "module_apply_tokens/bert/encoder/strided_slice/stack", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"end_mask": {"i": "0"}, "Index": {"type": "DT_INT32"}, "T": {"type": "DT_INT32"}, "shrink_axis_mask": {"i": "1"}, "begin_mask": {"i": "0"}, "ellipsis_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}}}, {"name": "module_apply_tokens/bert/encoder/strided_slice_5", "op": "StridedSlice", "input": ["module_apply_tokens/bert/encoder/Shape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "module_apply_tokens/bert/encoder/strided_slice_1/stack_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"end_mask": {"i": "0"}, "T": {"type": "DT_INT32"}, "Index": {"type": "DT_INT32"}, "shrink_axis_mask": {"i": "1"}, "ellipsis_mask": {"i": "0"}, "begin_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape", "op": "Pack", "input": ["module_apply_tokens/bert/encoder/strided_slice_4", "module_apply_tokens/bert/encoder/strided_slice_5", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape/2", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape/3"], "attr": {"N": {"i": "4"}, "T": {"type": "DT_INT32"}, "axis": {"i": "0"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/strided_slice_4", "module_apply_tokens/bert/encoder/strided_slice_5"], "attr": {"T": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/Reshape_13/shape", "op": "Pack", "input": ["module_apply_tokens/bert/encoder/strided_slice_4", "module_apply_tokens/bert/encoder/strided_slice_5", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape/1"], "attr": {"T": {"type": "DT_INT32"}, "axis": {"i": "0"}, "N": {"i": "3"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape", "op": "Pack", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape/1"], "attr": {"T": {"type": "DT_INT32"}, "axis": {"i": "0"}, "N": {"i": "2"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_0/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/MatMul", "module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/Mul", "module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_0/attention/self/transpose_2"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/self/Reshape_3", "module/bert/encoder/layer_0/attention/output/dense/kernel", "module/bert/encoder/layer_0/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/Reshape_1", "module_apply_tokens/bert/encoder/layer_0/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_0/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_0/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_0/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_0/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_0/intermediate/dense/kernel", "module/bert/encoder/layer_0/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x"], "attr": {"T": {"type": "DT_FLOAT"}, "_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/Pow", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/add", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/Tanh", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_0/intermediate/dense/mul_2"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_0/intermediate/dense/mul_3", "module/bert/encoder/layer_0/output/dense/kernel", "module/bert/encoder/layer_0/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_0/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_0/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_0/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_0/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_0/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_0/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_1/attention/self/query/kernel", "module/bert/encoder/layer_1/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_1/attention/self/key/kernel", "module/bert/encoder/layer_1/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_1/attention/self/value/kernel", "module/bert/encoder/layer_1/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_1/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/MatMul", "module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/Mul", "module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_1/attention/self/transpose_2"], "attr": {"T": {"type": "DT_FLOAT"}, "adj_x": {"b": false}, "adj_y": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/self/Reshape_3", "module/bert/encoder/layer_1/attention/output/dense/kernel", "module/bert/encoder/layer_1/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_1/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_1/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_1/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_1/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_1/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_1/intermediate/dense/kernel", "module/bert/encoder/layer_1/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/Pow", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/add", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/Tanh", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_1/intermediate/dense/mul_2"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_1/intermediate/dense/mul_3", "module/bert/encoder/layer_1/output/dense/kernel", "module/bert/encoder/layer_1/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_1/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_1/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_1/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_1/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_1/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_1/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_2/attention/self/query/kernel", "module/bert/encoder/layer_2/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_2/attention/self/key/kernel", "module/bert/encoder/layer_2/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_2/attention/self/value/kernel", "module/bert/encoder/layer_2/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_2/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "module_apply_tokens/bert/encoder/layer_2/attention/self/MatMul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "module_apply_tokens/bert/encoder/layer_2/attention/self/Mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_2/attention/self/transpose_2"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/self/Reshape_3", "module/bert/encoder/layer_2/attention/output/dense/kernel", "module/bert/encoder/layer_2/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_2/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_2/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_2/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_2/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_2/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_2/intermediate/dense/kernel", "module/bert/encoder/layer_2/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_2/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/BiasAdd"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/Pow"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_2/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_2/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_2/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_2/intermediate/dense/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}, "_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_2/intermediate/dense/mul_3", "module/bert/encoder/layer_2/output/dense/kernel", "module/bert/encoder/layer_2/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_2/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_2/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_2/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_2/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_2/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_2/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_3/attention/self/query/kernel", "module/bert/encoder/layer_3/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_3/attention/self/key/kernel", "module/bert/encoder/layer_3/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_3/attention/self/value/kernel", "module/bert/encoder/layer_3/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_3/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "module_apply_tokens/bert/encoder/layer_3/attention/self/MatMul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "module_apply_tokens/bert/encoder/layer_3/attention/self/Mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_3/attention/self/transpose_2"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/self/Reshape_3", "module/bert/encoder/layer_3/attention/output/dense/kernel", "module/bert/encoder/layer_3/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_3/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_3/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_3/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_3/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_3/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_3/intermediate/dense/kernel", "module/bert/encoder/layer_3/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_3/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/BiasAdd"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/Pow"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_3/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_3/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_3/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_3/intermediate/dense/mul_2"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_3/intermediate/dense/mul_3", "module/bert/encoder/layer_3/output/dense/kernel", "module/bert/encoder/layer_3/output/dense/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_3/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_3/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_3/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_3/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_3/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_3/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_4/attention/self/query/kernel", "module/bert/encoder/layer_4/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_4/attention/self/key/kernel", "module/bert/encoder/layer_4/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_4/attention/self/value/kernel", "module/bert/encoder/layer_4/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_4/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "module_apply_tokens/bert/encoder/layer_4/attention/self/MatMul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "module_apply_tokens/bert/encoder/layer_4/attention/self/Mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_4/attention/self/transpose_2"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/self/Reshape_3", "module/bert/encoder/layer_4/attention/output/dense/kernel", "module/bert/encoder/layer_4/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_4/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_4/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_4/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_4/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_4/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_4/intermediate/dense/kernel", "module/bert/encoder/layer_4/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_4/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/BiasAdd"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/Pow"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_4/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_4/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_4/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_4/intermediate/dense/mul_2"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_4/intermediate/dense/mul_3", "module/bert/encoder/layer_4/output/dense/kernel", "module/bert/encoder/layer_4/output/dense/bias"], "device": "/device:CPU:0", "attr": {"fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_4/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_4/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_4/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_4/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_4/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_4/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_5/attention/self/query/kernel", "module/bert/encoder/layer_5/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_5/attention/self/key/kernel", "module/bert/encoder/layer_5/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_5/attention/self/value/kernel", "module/bert/encoder/layer_5/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_5/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "module_apply_tokens/bert/encoder/layer_5/attention/self/MatMul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "module_apply_tokens/bert/encoder/layer_5/attention/self/Mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_5/attention/self/transpose_2"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/self/Reshape_3", "module/bert/encoder/layer_5/attention/output/dense/kernel", "module/bert/encoder/layer_5/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_5/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_5/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_5/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_5/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_5/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_5/intermediate/dense/kernel", "module/bert/encoder/layer_5/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_5/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/BiasAdd"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/Pow"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_5/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_5/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_5/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_5/intermediate/dense/mul_2"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_5/intermediate/dense/mul_3", "module/bert/encoder/layer_5/output/dense/kernel", "module/bert/encoder/layer_5/output/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_5/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_5/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_5/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_5/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_5/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_5/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_6/attention/self/query/kernel", "module/bert/encoder/layer_6/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_6/attention/self/key/kernel", "module/bert/encoder/layer_6/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_6/attention/self/value/kernel", "module/bert/encoder/layer_6/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_6/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "module_apply_tokens/bert/encoder/layer_6/attention/self/MatMul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "module_apply_tokens/bert/encoder/layer_6/attention/self/Mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_6/attention/self/transpose_2"], "attr": {"T": {"type": "DT_FLOAT"}, "adj_x": {"b": false}, "adj_y": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/self/Reshape_3", "module/bert/encoder/layer_6/attention/output/dense/kernel", "module/bert/encoder/layer_6/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_6/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_6/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_6/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_6/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_6/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_6/intermediate/dense/kernel", "module/bert/encoder/layer_6/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_6/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/BiasAdd"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/Pow"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_6/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_6/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_6/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_6/intermediate/dense/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}, "_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_6/intermediate/dense/mul_3", "module/bert/encoder/layer_6/output/dense/kernel", "module/bert/encoder/layer_6/output/dense/bias"], "device": "/device:CPU:0", "attr": {"fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_6/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_6/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_6/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_6/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_6/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_6/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_7/attention/self/query/kernel", "module/bert/encoder/layer_7/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_7/attention/self/key/kernel", "module/bert/encoder/layer_7/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_7/attention/self/value/kernel", "module/bert/encoder/layer_7/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_7/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "module_apply_tokens/bert/encoder/layer_7/attention/self/MatMul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "module_apply_tokens/bert/encoder/layer_7/attention/self/Mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_7/attention/self/transpose_2"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/self/Reshape_3", "module/bert/encoder/layer_7/attention/output/dense/kernel", "module/bert/encoder/layer_7/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_7/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_7/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_7/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_7/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_7/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_7/intermediate/dense/kernel", "module/bert/encoder/layer_7/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_7/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/BiasAdd"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/Pow"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_7/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_7/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_7/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_7/intermediate/dense/mul_2"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_7/intermediate/dense/mul_3", "module/bert/encoder/layer_7/output/dense/kernel", "module/bert/encoder/layer_7/output/dense/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_7/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_7/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_7/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_7/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_7/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_7/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_8/attention/self/query/kernel", "module/bert/encoder/layer_8/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_8/attention/self/key/kernel", "module/bert/encoder/layer_8/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_8/attention/self/value/kernel", "module/bert/encoder/layer_8/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_8/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "module_apply_tokens/bert/encoder/layer_8/attention/self/MatMul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "module_apply_tokens/bert/encoder/layer_8/attention/self/Mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_8/attention/self/transpose_2"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/self/Reshape_3", "module/bert/encoder/layer_8/attention/output/dense/kernel", "module/bert/encoder/layer_8/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_8/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_8/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_8/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_8/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_8/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_8/intermediate/dense/kernel", "module/bert/encoder/layer_8/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_8/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/BiasAdd"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/Pow"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_8/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_8/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_8/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_8/intermediate/dense/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}, "_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_8/intermediate/dense/mul_3", "module/bert/encoder/layer_8/output/dense/kernel", "module/bert/encoder/layer_8/output/dense/bias"], "device": "/device:CPU:0", "attr": {"epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_8/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_8/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_8/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_8/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_8/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_8/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_9/attention/self/query/kernel", "module/bert/encoder/layer_9/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_9/attention/self/key/kernel", "module/bert/encoder/layer_9/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_9/attention/self/value/kernel", "module/bert/encoder/layer_9/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_9/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "module_apply_tokens/bert/encoder/layer_9/attention/self/MatMul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1", "module_apply_tokens/bert/encoder/layer_9/attention/self/Mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_9/attention/self/transpose_2"], "attr": {"T": {"type": "DT_FLOAT"}, "adj_x": {"b": false}, "adj_y": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/self/Reshape_3", "module/bert/encoder/layer_9/attention/output/dense/kernel", "module/bert/encoder/layer_9/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_9/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_9/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_9/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_9/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_9/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_9/intermediate/dense/kernel", "module/bert/encoder/layer_9/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_9/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/BiasAdd"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/Pow"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_9/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_9/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_9/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_9/intermediate/dense/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}, "_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_9/intermediate/dense/mul_3", "module/bert/encoder/layer_9/output/dense/kernel", "module/bert/encoder/layer_9/output/dense/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_9/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_9/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_9/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_9/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_9/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_9/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_10/attention/self/query/kernel", "module/bert/encoder/layer_10/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_10/attention/self/key/kernel", "module/bert/encoder/layer_10/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_10/attention/self/value/kernel", "module/bert/encoder/layer_10/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"T": {"type": "DT_FLOAT"}, "Tperm": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_10/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/MatMul", "module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/Mul", "module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_10/attention/self/transpose_2"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/self/Reshape_3", "module/bert/encoder/layer_10/attention/output/dense/kernel", "module/bert/encoder/layer_10/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_10/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_10/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_10/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_10/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_10/intermediate/dense/kernel", "module/bert/encoder/layer_10/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x"], "attr": {"T": {"type": "DT_FLOAT"}, "_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/Pow", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/add", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/Tanh", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_10/intermediate/dense/mul_2"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_10/intermediate/dense/mul_3", "module/bert/encoder/layer_10/output/dense/kernel", "module/bert/encoder/layer_10/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_10/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_10/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_10/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_10/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_10/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_10/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/query/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_11/attention/self/query/kernel", "module/bert/encoder/layer_11/attention/self/query/bias"], "device": "/device:CPU:0", "attr": {"epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/key/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_11/attention/self/key/kernel", "module/bert/encoder/layer_11/attention/self/key/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/value/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_11/attention/self/value/kernel", "module/bert/encoder/layer_11/attention/self/value/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/query/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_1", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/key/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_2", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/value/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose_1", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose_2", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_2", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/MatMul", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/transpose", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose_1"], "attr": {"adj_x": {"b": false}, "adj_y": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/MatMul", "module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Mul", "module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Softmax", "op": "Softmax", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/MatMul_1", "op": "BatchMatMul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Softmax", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose_2"], "attr": {"T": {"type": "DT_FLOAT"}, "adj_x": {"b": false}, "adj_y": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose_3", "op": "Transpose", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/MatMul_1", "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm"], "attr": {"Tperm": {"type": "DT_INT32"}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/transpose_3", "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3", "module/bert/encoder/layer_11/attention/output/dense/kernel", "module/bert/encoder/layer_11/attention/output/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_11/attention/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_11/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_11/attention/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_11/attention/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_11/attention/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1", "module/bert/encoder/layer_11/intermediate/dense/kernel", "module/bert/encoder/layer_11/intermediate/dense/bias"], "device": "/device:CPU:0", "attr": {"transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow", "op": "Pow", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/BiasAdd", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Tanh", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_3", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1", "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_3", "module/bert/encoder/layer_11/output/dense/kernel", "module/bert/encoder/layer_11/output/dense/bias"], "device": "/device:CPU:0", "attr": {"T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/layer_11/output/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/moments/mean", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_11/output/add", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference", "op": "SquaredDifference", "input": ["module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/moments/mean", "module_apply_tokens/bert/encoder/layer_11/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/moments/variance", "op": "Mean", "input": ["module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference", "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim"], "attr": {"T": {"type": "DT_FLOAT"}, "keep_dims": {"b": true}, "Tidx": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/add", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/moments/variance"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt", "op": "Rsqrt", "input": ["module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul", "op": "Mul", "input": ["module/bert/encoder/layer_11/output/LayerNorm/gamma", "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/moments/mean"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1", "op": "Mul", "input": ["module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul", "module_apply_tokens/bert/encoder/layer_11/output/add"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/sub", "op": "Sub", "input": ["module/bert/encoder/layer_11/output/LayerNorm/beta", "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1", "op": "Add", "input": ["module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1", "module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/sub"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/encoder/Reshape_13", "op": "Reshape", "input": ["module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1", "module_apply_tokens/bert/encoder/Reshape_13/shape"], "attr": {"T": {"type": "DT_FLOAT"}, "Tshape": {"type": "DT_INT32"}}}, {"name": "module_apply_tokens/bert/pooler/strided_slice", "op": "StridedSlice", "input": ["module_apply_tokens/bert/encoder/Reshape_13", "module_apply_tokens/bert/pooler/strided_slice/stack", "module_apply_tokens/bert/pooler/strided_slice/stack_1", "module_apply_tokens/bert/pooler/strided_slice/stack_2"], "attr": {"begin_mask": {"i": "5"}, "ellipsis_mask": {"i": "0"}, "new_axis_mask": {"i": "0"}, "end_mask": {"i": "5"}, "T": {"type": "DT_FLOAT"}, "Index": {"type": "DT_INT32"}, "shrink_axis_mask": {"i": "0"}}}, {"name": "module_apply_tokens/bert/pooler/Squeeze", "op": "Squeeze", "input": ["module_apply_tokens/bert/pooler/strided_slice"], "attr": {"squeeze_dims": {"list": {"i": ["1"]}}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/pooler/dense/BiasAdd", "op": "_FusedMatMul", "input": ["module_apply_tokens/bert/pooler/Squeeze", "module/bert/pooler/dense/kernel", "module/bert/pooler/dense/bias"], "device": "/device:CPU:0", "attr": {"num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}, "transpose_b": {"b": false}, "T": {"type": "DT_FLOAT"}}}, {"name": "module_apply_tokens/bert/pooler/dense/Tanh", "op": "Tanh", "input": ["module_apply_tokens/bert/pooler/dense/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "loss/dropout/Shape", "op": "Shape", "input": ["module_apply_tokens/bert/pooler/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}, "out_type": {"type": "DT_INT32"}}}, {"name": "loss/dropout/random_uniform/RandomUniform", "op": "RandomUniform", "input": ["loss/dropout/Shape"], "attr": {"T": {"type": "DT_INT32"}, "dtype": {"type": "DT_FLOAT"}, "seed2": {"i": "0"}, "seed": {"i": "0"}}}, {"name": "loss/dropout/GreaterEqual", "op": "GreaterEqual", "input": ["loss/dropout/random_uniform/RandomUniform", "loss/dropout/rate"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "loss/dropout/Cast", "op": "Cast", "input": ["loss/dropout/GreaterEqual"], "attr": {"Truncate": {"b": false}, "DstT": {"type": "DT_FLOAT"}, "SrcT": {"type": "DT_BOOL"}}}, {"name": "loss/dropout/mul", "op": "Mul", "input": ["loss/dropout/Cast", "loss/dropout/truediv"], "attr": {"_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}, "T": {"type": "DT_FLOAT"}}}, {"name": "loss/dropout/mul_1", "op": "Mul", "input": ["loss/dropout/mul", "module_apply_tokens/bert/pooler/dense/Tanh"], "attr": {"T": {"type": "DT_FLOAT"}, "_grappler_ArithmeticOptimizer_MinimizeBroadcasts": {"b": true}}}, {"name": "loss/BiasAdd", "op": "_FusedMatMul", "input": ["loss/dropout/mul_1", "output_weights", "output_bias"], "device": "/device:CPU:0", "attr": {"transpose_b": {"b": true}, "T": {"type": "DT_FLOAT"}, "num_args": {"i": "1"}, "epsilon": {"f": 0.0}, "fused_ops": {"list": {"s": ["Qmlhc0FkZA=="]}}, "transpose_a": {"b": false}}}, {"name": "loss/LogSoftmax", "op": "LogSoftmax", "input": ["loss/BiasAdd"], "attr": {"T": {"type": "DT_FLOAT"}}}, {"name": "loss/ArgMax", "op": "ArgMax", "input": ["loss/LogSoftmax", "loss/ArgMax/dimension"], "attr": {"T": {"type": "DT_FLOAT"}, "output_type": {"type": "DT_INT32"}, "Tidx": {"type": "DT_INT32"}}}, {"name": "loss/Squeeze", "op": "Squeeze", "input": ["loss/ArgMax"], "attr": {"squeeze_dims": {"list": {}}, "T": {"type": "DT_INT32"}}}], "versions": {"producer": 175}}, "weightsManifest": [{"paths": ["group1-shard1of105.bin", "group1-shard2of105.bin", "group1-shard3of105.bin", "group1-shard4of105.bin", "group1-shard5of105.bin", "group1-shard6of105.bin", "group1-shard7of105.bin", "group1-shard8of105.bin", "group1-shard9of105.bin", "group1-shard10of105.bin", "group1-shard11of105.bin", "group1-shard12of105.bin", "group1-shard13of105.bin", "group1-shard14of105.bin", "group1-shard15of105.bin", "group1-shard16of105.bin", "group1-shard17of105.bin", "group1-shard18of105.bin", "group1-shard19of105.bin", "group1-shard20of105.bin", "group1-shard21of105.bin", "group1-shard22of105.bin", "group1-shard23of105.bin", "group1-shard24of105.bin", "group1-shard25of105.bin", "group1-shard26of105.bin", "group1-shard27of105.bin", "group1-shard28of105.bin", "group1-shard29of105.bin", "group1-shard30of105.bin", "group1-shard31of105.bin", "group1-shard32of105.bin", "group1-shard33of105.bin", "group1-shard34of105.bin", "group1-shard35of105.bin", "group1-shard36of105.bin", "group1-shard37of105.bin", "group1-shard38of105.bin", "group1-shard39of105.bin", "group1-shard40of105.bin", "group1-shard41of105.bin", "group1-shard42of105.bin", "group1-shard43of105.bin", "group1-shard44of105.bin", "group1-shard45of105.bin", "group1-shard46of105.bin", "group1-shard47of105.bin", "group1-shard48of105.bin", "group1-shard49of105.bin", "group1-shard50of105.bin", "group1-shard51of105.bin", "group1-shard52of105.bin", "group1-shard53of105.bin", "group1-shard54of105.bin", "group1-shard55of105.bin", "group1-shard56of105.bin", "group1-shard57of105.bin", "group1-shard58of105.bin", "group1-shard59of105.bin", "group1-shard60of105.bin", "group1-shard61of105.bin", "group1-shard62of105.bin", "group1-shard63of105.bin", "group1-shard64of105.bin", "group1-shard65of105.bin", "group1-shard66of105.bin", "group1-shard67of105.bin", "group1-shard68of105.bin", "group1-shard69of105.bin", "group1-shard70of105.bin", "group1-shard71of105.bin", "group1-shard72of105.bin", "group1-shard73of105.bin", "group1-shard74of105.bin", "group1-shard75of105.bin", "group1-shard76of105.bin", "group1-shard77of105.bin", "group1-shard78of105.bin", "group1-shard79of105.bin", "group1-shard80of105.bin", "group1-shard81of105.bin", "group1-shard82of105.bin", "group1-shard83of105.bin", "group1-shard84of105.bin", "group1-shard85of105.bin", "group1-shard86of105.bin", "group1-shard87of105.bin", "group1-shard88of105.bin", "group1-shard89of105.bin", "group1-shard90of105.bin", "group1-shard91of105.bin", "group1-shard92of105.bin", "group1-shard93of105.bin", "group1-shard94of105.bin", "group1-shard95of105.bin", "group1-shard96of105.bin", "group1-shard97of105.bin", "group1-shard98of105.bin", "group1-shard99of105.bin", "group1-shard100of105.bin", "group1-shard101of105.bin", "group1-shard102of105.bin", "group1-shard103of105.bin", "group1-shard104of105.bin", "group1-shard105of105.bin"], "weights": [{"name": "loss/dropout/rate", "shape": [], "dtype": "float32"}, {"name": "loss/dropout/truediv", "shape": [], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/Pow/y", "shape": [], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul/x", "shape": [], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_1/x", "shape": [], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/output/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/output/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/self/query/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/self/query/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/self/key/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/self/key/bias", "shape": [768], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Mul/y", "shape": [], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/mul_1/y", "shape": [], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/ones/packed/2", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/encoder/Reshape_1/shape", "shape": [2], "dtype": "int32"}, {"name": "module/bert/encoder/layer_0/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_0/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_1/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_2/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_3/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_4/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_5/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_6/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_7/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_8/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_9/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_10/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/self/value/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/self/value/bias", "shape": [768], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape/2", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape/shape/3", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/transpose/perm", "shape": [4], "dtype": "int32"}, {"name": "module/bert/encoder/layer_11/attention/output/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/attention/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/intermediate/dense/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/intermediate/dense/bias", "shape": [3072], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/mul_2/x", "shape": [], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/output/dense/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "module/bert/encoder/layer_11/output/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "module/bert/embeddings/LayerNorm/beta", "shape": [768], "dtype": "float32"}, {"name": "module/bert/embeddings/LayerNorm/gamma", "shape": [768], "dtype": "float32"}, {"name": "module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/y", "shape": [], "dtype": "float32"}, {"name": "module/bert/embeddings/position_embeddings", "shape": [512, 768], "dtype": "float32"}, {"name": "module_apply_tokens/bert/embeddings/one_hot/depth", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/intermediate/dense/add_1/x", "shape": [], "dtype": "float32"}, {"name": "module_apply_tokens/bert/embeddings/one_hot/off_value", "shape": [], "dtype": "float32"}, {"name": "module/bert/embeddings/token_type_embeddings", "shape": [2, 768], "dtype": "float32"}, {"name": "module/bert/embeddings/word_embeddings", "shape": [30522, 768], "dtype": "float32"}, {"name": "module_apply_tokens/bert/embeddings/embedding_lookup/axis", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/encoder/strided_slice/stack", "shape": [1], "dtype": "int32"}, {"name": "module_apply_tokens/bert/embeddings/Reshape_1/shape", "shape": [1], "dtype": "int32"}, {"name": "module_apply_tokens/bert/encoder/strided_slice_1/stack_1", "shape": [1], "dtype": "int32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/ExpandDims/dim", "shape": [1], "dtype": "int32"}, {"name": "module_apply_tokens/bert/encoder/layer_11/attention/self/Reshape_3/shape/1", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/pooler/strided_slice/stack", "shape": [3], "dtype": "int32"}, {"name": "module_apply_tokens/bert/pooler/strided_slice/stack_1", "shape": [3], "dtype": "int32"}, {"name": "module_apply_tokens/bert/pooler/strided_slice/stack_2", "shape": [3], "dtype": "int32"}, {"name": "module/bert/pooler/dense/kernel", "shape": [768, 768], "dtype": "float32"}, {"name": "module/bert/pooler/dense/bias", "shape": [768], "dtype": "float32"}, {"name": "output_weights", "shape": [2, 768], "dtype": "float32"}, {"name": "output_bias", "shape": [2], "dtype": "float32"}, {"name": "loss/ArgMax/dimension", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/embeddings/Slice/begin", "shape": [2], "dtype": "int32"}, {"name": "module_apply_tokens/bert/embeddings/Slice/size/1", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/embeddings/Reshape_3/shape/0", "shape": [], "dtype": "int32"}, {"name": "module_apply_tokens/bert/embeddings/Reshape_3/shape/2", "shape": [], "dtype": "int32"}]}]}